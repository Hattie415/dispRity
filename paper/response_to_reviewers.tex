\documentclass[12pt,letterpaper]{article}

%Packages
\usepackage{pdflscape}
\usepackage{fixltx2e}
\usepackage{textcomp}
\usepackage{fullpage}
\usepackage{float}
\usepackage{latexsym}
\usepackage{url}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{array}
\usepackage[version=3]{mhchem}
\usepackage{ifthen}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage{amstext}
\usepackage{enumerate}
\usepackage[osf]{mathpazo}
\usepackage{dcolumn}
\usepackage{lineno}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\pagenumbering{arabic}

%Pagination style and stuff
%\linespread{2} 

\raggedright
\setlength{\parindent}{0.5in}
\setcounter{secnumdepth}{0} 
\renewcommand{\section}[1]{%
\bigskip
\begin{center}
\begin{Large}
\normalfont\scshape #1
\medskip
\end{Large}
\end{center}}
\renewcommand{\subsection}[1]{%
\bigskip
\begin{center}
\begin{large}
\normalfont\itshape #1
\end{large}
\end{center}}
\renewcommand{\subsubsection}[1]{%
\vspace{2ex}
\noindent
\textit{#1.}---}
\renewcommand{\tableofcontents}{}

\setlength\parindent{0pt}

\begin{document}

\textbf{RE: MEE-17-08-729 }\\
\bigskip
Dear Dr Vamosi,\\
\bigskip

I am very grateful to the four referees for their helpful and constructive comments, which I believe have helped me to significantly improve the \texttt{dispRity} package and this associated package description paper.
I have taken all of their comments on board, and respond to their points in details below.
For improving clarity in this document, reviewers comments are displayed in blue, my responses in normal text and the changes to the manuscript in italic.
Also, I've uploaded two versions of the revised manuscript: both have the exact same content but one has all the changes and additions to the main text highlighted in yellow to help with reviewing.

% ~~~~~~~~~~~~~~~~~~~~~~~~
%
% REVIEWER 1
%
% ~~~~~~~~~~~~~~~~~~~~~~~~


\section{Reviewer 1}

\begin{enumerate}

\item{\textcolor{blue}{While I understand that the author is writing a package that has many diverse capabilities and is presented to be useful to a wide range of disciplines, it is too vague in too many places to be helpful in its current state.
For example, the line in the abstract “It is then possible to use a summary metrics for measuring some properties of this space for some group of species and compare them.”.
“Some properties” is too vague without any qualifiers to be useful. But I believe that with revision, taking into account the issues of clarity, this will be an important addition to the available analytical tools for Biologists.}}

I have changed the terms used in the abstract and proposed more specific examples for clarity:

\textit{It is then possible to measure divers aspects of the distribution of some observation (e.g. species) in this space. For example, if studying morphology, one can create a morphospace for two groups of species, measure the volume occupied by each of these groups and then test whether these two volumes are significantly different or not.} lines 6-10.

The changes have also been made throughout the manuscript as generally suggested by all four reviewers.

\item{\textcolor{blue}{My main concern is that what disparity actually means is left to the reader’s imagination – it is not defined or discussed anywhere.
Disparity simply means lack of similarity or equality.
While the author is probably considering the dispersion of points in a multidimensional space as a measure of dissimilarity, it is important to realise the ambiguity of the word and more explanation is needed early in the introduction (and foremost in the abstract).
Specifically, the lines 58-61 need to be revised, as they simply don’t convey to the reader what is being presented here as disparity.
Say what “specific aspect of it [multidimensional space]” you are referring to.
Also, the different definitions of disparity alluded to on lines 61-63 should be summarised.
Furthermore, the manuscript is lacking a table summarising the metrics of disparity that this package can work with (which I suspect it was supposed to have).}}
\label{define_disparity}

Apologies for the omission of the table summarising the metrics which is now properly included in the manuscript (see reviewer 1, minor comment \ref{table_missing})
As reviewer 4 (major comment \ref{nebulous}) also underlines: ``disparity is a broad, nebulous concept''.
This observation was the genesis for this package and I am currently working on a collaborative review to define the borders (or the absence thereof) of this concept.
I feel that explaining this would be out of the scope of this software description paper.
However, I have tried to give specific examples each time I refer to disparity as a way to measure these ``specific aspect of the space'' and I have also added a clearer definition of what I mean by disparity throughout this manuscript.

I rewrote the part in the introducing disparity as follows:

\textit{One can then measure how the observations are distributed within this space to answer related questions (e.g. ``does group A occupies more space than group B?''). This requires the definition of a proxy for space occupancy: the disparity metric (or index; Hopkins and Gerber, 2017) which can be measured in a multitude of ways. For example, one could use a metric based on the variance or the range of each axis of space (Wills, 2001; Ciampaglio et al., 2001), a distance (e.g. Euclidean) measured between observations (Foote, 1993, 1996), a more direct approximation of the hyper volume (Cornwell et al., 2006; Donohue et al., 2013), or many more (e.g. Navarro, 2003).} lines 60-67.

\item{\textcolor{blue}{Another concern I have is about how this R package sits within the current analytical toolkit available.
How does this new package relate to existing packages available for R?
Claddis and geomorph are mentioned and discussed because they deal with bespoke data formats that need to be dealt with prior to analysis.
But are there others?
How does the package relate to the ‘vegan’ R package for multivariate analysis of ecological communities?
Within there are metrics for community dissimilarity, metrics from ordinations etc.
Vegan is a popular package for analysis of multivariate datasets and seems to be relevant here with similar functionalities but not discussed.
Similarly, the R package ‘diverse’ has a function called disparity, and the ‘geiger’ function disparity implements the disparity-through-time. }}

I have added two wrapper functions to use the popular functions \texttt{vegan::adonis} and \texttt{geiger::dtt} to the package (\texttt{dispRity.adonis} and \texttt{dispRity.dtt}).
Also, I have generalised the distances calculations using the \texttt{vegan::vegdist} function that allows for more distances than \texttt{stats::dist} to be calculated.

I've updated the manual and the example to describe these new functions:

\textit{Similarly to the example above, it is also possible to statistically test this hypothesis using, for example, permutational multivariate ANOVA (PERMANOVA; Anderson, 2001b) through the adonis.disprity function that is a wrapper of the vegan::adonis function (Oksanen et al., 2007) for dispRity objects [TABLE 4]. To answer our specific question above: yes there is an effect of time on morphological disparity (an increase) in this dataset. Note that is this case, the function calls different warnings on the usage of such test and the eventual data not used in the test. Additionally, the test is not applied to the bootstrapped data and thus might be sensitive to outliers and sampling size.} lines 351-361.

\end{enumerate}

\subsection{Reviewer 1 - Minor comments}

\begin{enumerate}

\item{\textcolor{blue}{The paper keywords are narrow and suggest a very particular use of disparity analyses (morphological disparity). The paper suggests there are broader applications and so these should be revised to include the diverse applications that the paper suggests. }}

I have broaden the keywords within the limits allowed by manuscript central for MEE publications. 

\item{\textcolor{blue}{Line 4 – changes ``in'' to ``to''. Line 6 – changes ``axis'' to ``axes''}}
\label{abstract_typo}

I have fixed these typos.

\item{\textcolor{blue}{Line 84 – Explain what the Procrustes variance is. And when is it appropriate and when is not appropriate? Be more specific.}}
\label{tone_down}

In \texttt{geomorph}, the procrustes variance is defined as the sum of the diagonal covariance matrix between each elements divided by the number of elements (or effectively the sum of the squared ordination values divided by the number of elements - see example in \texttt{R} for \texttt{?dispRity::geomorph.ordination}).
Using this disparity metric is appropriate for testing volume based hypothesis (e.g. Does group A occupies more morphospace than group B?) but does not allow to test position based hypothesis (e.g. Does group A occupies a different part of the morphospace than group B).
For example, one might find out that group A and B have the same volume but that doesn't tell us if they occupy the same position in the morphospace.

I've highlighted this in the text:

\textit{For example, in the excellent and widely used} \texttt{geomorph} \textit{package, morphological disparity analysis uses the} \texttt{morphol.disparity} \textit{function that defines the multidimensional space as the ordination of the Procrustes transform of the morphometric data, the disparity metric as the relative sum of the diagonal of the covariance of the ordination scores (Procrustes variance), and uses permutation tests (Zelditch et al., 2012; Adams and Otarola-Castillo, 2013; Adams et al., 2017). This is ideal for testing volume based hypothesis (e.g. does groups A and B have the same volume?), but in other cases may not be appropriate in non-volume based hypothesis, e.g. does groups A and B occupy the same location?).} lines 85-93.

\item{\textcolor{blue}{Lines 98-100 – Suggest changing this to be specific: “calculates a disparity metric from the space”, and “analyse the resulting disparity object through hypothesis testing and visualisation”}}

I have changed the sentence following the reviewer's suggestion.

\item{\textcolor{blue}{Line 116 – “Table ??” = should have been caught during proofreading. Furthermore, there is no table included in the manuscript that details the implemented metrics, and this is an important part of the paper sadly omitted in this submission.}}
\label{table_missing}

I sincerely apologise for the omission of the Table! It is now included in the new version of the manuscript with the currently implemented metrics description.
I would also like to underline that although not all usual disparity metrics are not represented in the table and in the package (by far!) the idea of the \texttt{dispRity} package and specifically the \texttt{metric} argument in the \texttt{dispRity} function is to allow users to come up with their \textit{own} metric.

For example, if one decides to use the relative ellipsoid hyper volume to the number of elements per group as a disparity metric (i.e. this metric could be used as a proxy for the average space occupancy per unit element - e.g. per taxa).
This would not be doable directly by using the implemented \texttt{ellipse.volume} function but would require the user to use a function like:\\
\texttt{dispRity(my\_data, metric = function(X) ellipse.volume(X)/nrows(X))}\\


\item{\textcolor{blue}{Lines 356-357 – This final sentence of the conclusion section is vague and does not add to the manuscript.}}
\label{remove_last_sentence}

I removed the last sentence.

\item{\textcolor{blue}{Figure 1 – Procrustes is a proper noun and requires a capital p. Is the Procrustes matrix a “Procrustes distance matrix” or a “Procrustes residuals matrix”? i.e. is it the shape variables after a Procrustes superimposition (latter) or the distances between individuals after a Procrustes superimposition (former)? Both are suitable inputs for ordination.}}

I meant both matrices (as this reviewers rightly points out they are suitable for ordination).
I have made this more clear in the figure caption.
On a more general note, the package now allows users to input any matrix (although the package does not provide warranty that the provided matrix is meaningful to the user's specific analysis).
I have added an example to the \texttt{dispRity} manual based on the \texttt{eurodist R} base dataset. 

\item{\textcolor{blue}{Figure 2 makes little sense without a summary of the kinds of disparity metrics available to the user, and needs more explanation with examples for each dimension level.}}

I've added a longer explanation of the different dimension-levels in the caption of the figure:

\textit{A dimension-level 3 matrix would be a metric resulting in a matrix (e.g. the function \texttt{stats::cor} to calculate the correlation between each dimension), a dimension-level 2 metric would result in a vector (i.e. a distribution, e.g. \texttt{dispRity::variances} which calculates the variance within each dimension) and a dimension-level 1 metric would result in a single value (e.g. \texttt{stats::sd} which calculates the standard deviation of the input matrix).}

\item{\textcolor{blue}{Table 1 – change to disparity-within-groups with hyphens as DTT below. Also add “shape” before data for geomorph.ordination, and perhaps a similar qualifier for Claddis.ordination.}}

I've added hyphens to disparity-within-group and ``\textit{shape data}'' and ``\textit{discrete morphological data}'' for the two ordinations functions in the table.

\end{enumerate}





% ~~~~~~~~~~~~~~~~~~~~~~~~
%
% REVIEWER 2
%
% ~~~~~~~~~~~~~~~~~~~~~~~~





\section{Reviewer 2}

\begin{enumerate}
\item{\textcolor{blue}{Firstly, features available in the package but not currently fully explained/highlighted.
Really the only major omission here is a more detailed description of the tools avilable under the "Data Simulations" section of the manuscript.
I suspect many users will find this the *most* useful feature of the package and the author should consider unpacking this section a bit more.
Perhaps adding an additional multipanel figure exhibitng some simulated spaces.}}
\label{simulations}

Reviewer 4 (minor comment \ref{remove_simulations}) suggested completely removing this section which conflicts directly with this suggestion.
The simulation protocols implemented here are already developed (and tested) in details in previous publications with new novel features attached to future publication.
For example the discrete data simulation protocol is described and detailed in Guillerme \& Cooper 2016 \textit{Mol Phyl Evol}, O’Reilly et al. 2016 \textit{Biol Let}, O'Reilly et al. 2017 \textit{Palaeontology} and Guillerme \& Brazeau \textit{in review}.
The implemented ordinated space simulations are theoretically described in Diaz et al. 2016 \textit{Nature} and will be used along with additional simulation features not implemented yet (including shape evolution) as part of a project currently in progress.
I am therefore inclined to follow reviewer's 4 suggestion rather than this one.

However, I have heavily edited the online manual to highlight the simulation functionalities implemented in the \texttt{dispRity} package: \url{https://rawgit.com/TGuillerme/dispRity/master/inst/gitbook/_book/making-stuff-up.html}.
The manual now has a chapter entirely dedicated to the data simulation functions with emphasis on both the methods used and the algorithms implemented (and illustrated with advanced examples).
%TODO: check typos in there.

\item{\textcolor{blue}{Secondly, problematic implementations.
Here there is again only one major issue, and that concerns the time-slicing options.
Initially it should be noted by the author how useful this feature could be in generating time series of disparity that are long enough for time series statistics to be applied.
Currently most palaeobiologists are stuck using binned data (e.g., Figure 4) which tends to lead to time series of insufficient length (here N = 3) to explore, for example, correlations with climate proxies (or some other hypothesised driver of morphological diversity).
Time-slicing could revolutionise the field by opening up data sets to such analyses and an example alongside the binning in Figure 4 should be considered.
However, the current implemented options are, in my view, deeply problematic.
Specifically, dispRity offers four options (L145-156), but in effect these all boil down to treating a point along a branch as either identical to the descendant (end of branch) or the ancestor (start of branch).
However, I think most biologists would treat such a value as more likely to be intermediate between these extremes and possessing some form of uncertainty depending on the generating model's assumptions (e.g., Brownian motion).
I don't mind offering a punctuated model (descendant value propagated back along branch) but some form of intermediate value should also exist.
Without this option data are likely to be biased, e.g., towards generating more "jagged" time series and perhaps more significant slice-to-slice changes (using the packages "test" functions) than are realistic (ie.e, type I errors).}}

The standard approach in palaeobiology relies on the following pipeline: (i) coding characters for tips; (ii) running ancestral states reconstructions for the nodes; (iii) ordinating the resulting matrix (usually via a PCO); (iv) measuring disparity from there (see Lloyd 2016 \textit{Biol J Lin Soc} for an excellent description of this pipeline).
I feel that the reviewer's suggestion of proposing more accurate models for ancestral states reconstructions and will technically not be doable after step (iii).
In fact, the ordination, to be meaningful as a ``morphospace'' should always be done on the full dataset.
I.e. no additional data should be added to the space \textit{a posteriori}.
In practice, the \textit{time.subset} function can only select between two information: the ancestral node (DELTRAN) and the descendant node/tip (ACCTRAN) along the edge since only the two of them are real objects in the morphospace.
It is therefore not possible to create an ancestral states reconstruction along the edge after running the ordination.

I have however modified the available models to better describe this limitation and I have added two new models that would approximate ancestral reconstruction along edges
I have modified the name of the two previous ``punctuated'' and ``gradual'' algorithms to ``random'' and ``proximity'' to reflect more accurately how they select either the ACCTRAN or DELTRAN information.
I've added two more accurate models (now named ``equal.split'' and ``gradual.split'') to reflect the changes along the branches.
These two algorithm now allows to use both the ACCTRAN and DELTRAN information with a linked probability to use either of them per bootstrap draw.
For example, the ``equal.split'' model will have a 0.5 probability of using either node information for each bootstrap draw; the ``gradual.split'' model transforms the branch length were the slice occurs into a probability of drawing either of the nodes information (e.g. if the slices occurs 3/4 along the branch from A to B, the model will draw the information from A and B with a probability of respectively 0.25 and 0.75).
For example, the median disparity over 1000 bootstrap pseudo-replication along the edge (AB) will integrate 0.75 information from A and 0.25 from B thus approximating the ``intermediate'' between A and B (when averaged ).

I've added these models descriptions in the manual and in the manuscript:

\begin{itemize}
    \item \textit{``random'' where the data chosen along the branch is randomly chosen between the descendant or the ancestor}
    \item \textit{``proximity'' where the data chosen along the branch is either the descendant or the ancestor depending on branch length}
    \item \textit{``equal.split'' where the data chosen along the branch is both the descendant and the ancestor with an even probability}
    \item \textit{``gradual.split'' where the data chosen along the branch is both the descendant and the ancestor with a probability depending on branch length}
\end{itemize}

\textit{Note that the four first models are a proxy for punctuated evolution: the selected data is always either the one of the descendant or the ancestor.
The two last models are a proxy for gradual evolution: the data from both the descendant and the ancestor is used with an associate probability.
These later models perform better when bootstrapped, effectively approximating the "intermediate" state between and the ancestor and the descendants (see below).
Finally, there is a trade-off between precision and accuracy when using the time-slicing method: a higher number of slices increases the precision of the disparity analysis but also increases the type II error (thus decreasing accuracy).} lines @@@

\item{\textcolor{blue}{An additional more minor implementation issue here concerns the "subsamples". Firstly, I would urge the author to reconsider this name as it implies subsampling (e.g., rarefaction) and not what is intended, i.e., subsets of the data (the term used on L124) or groups of taxa. However, a more pressing issue is that I do not see any restrictions on overlap between these "subsamples" and indeed in the case of time-binning this is suggested as a "pro" (L138). Although in cases such as time-binning it is obviously sensible to allow taxa to appear in multiple "subsamples" this changes the assumptions of a statistical test looking for differences between samples, i.e., as overlap increases so would type II errors. I suggest the author consider at least a warning to users in such circumstances.}}

I've changed ``subsample'' to ``subset'' throughout the package, the manual and the paper.

I also agree with this comment: this method creates a trade-off between the number of slices and the type II errors: %TOCHEK@@@
(1) too few slices decrease resolution and veer towards the time binning (which could increase "significance" by comparing too different time subsamples);
(2) too many slices will increase the resolution be will create much more pseudo replication and thus increase type II error.

A more detailed description and test of these models might be out of the scope of this package description paper but is currently in development for a special issue paper to be submitted to \textit{Palaeontology} as part as a special symposium for the Palaeontological Association annual meeting 2017 in collaboration with Natalie Cooper (\url{http://www.palass.org/meetings-events/annual-meeting/2017/annual-meeting-2017-london-symposium-abstracts}).

I've added a warning in the manual and the manuscript:

\textit{Finally, there is a trade-off between precision and accuracy when using the time-slicing method: a higher number of slices increases the precision of the disparity analysis but also increases the type II error (thus decreasing accuracy).} line @@@

\item{\textcolor{blue}{Finally, additions the author could consider adding to the package. These are mostly minor, but more numerous. Some of these are simple caveats for limitations to the package. For example, disparity metrics can be generated from, for example, a discrete-character taxon matrix directly, or the distance matrix given to the ordination (e.g., the weighted mean pairwise distance metric used in Close et al. 2015, cited). Because the package only deals with matrices generated by the ordination itself these metrics are beyond its scope, although are of potential value to disparity analysis more broadly. Specifically, the Close et al. (2015) metric can be applied to an incomplete matrix, but principal coordinates/classic multidimensional scaling requires a complete distance matrix and hence taxa would have to be pruned to generate an ordination, but can be retained if using a pre-ordination metric. In a similar vein, although the package allows bootstrapping of the space it could also be useful for the raw data itself to be bootstrapped, e.g., the set of measurements used to generate a principal components analysis. It might be helpful for the author just to make it clear (with a sentence or two) that these are things a user might want to attempt, but the package cannot (reasonably) do.}}

I have updated the package's structure to be able to deal with any type of matrix as long as rows are the elements (e.g. taxa).
It is now possible to perform the whole pipelined analysis (including bootstrapping) on non-ordinated matrices.

I've reflected these changes in the manual with a subsection in the chapter ``Specific tutorials'' and in manuscript as follows:

\textit{Note that the input matrix is not restricted to an ordinated matrix but can be any kind of matrix as long as its rows represent elements (e.g. the multidimensional space can be a distance matrixl; Close et al., 2015).} @@@


\item{\textcolor{blue}{Picking up on the first point from above, there are also additional post-ordination disparity metrics that have been used in the literature but are not available here. For example, hypercube volume, minimum spanning tree length etc. I would also urge the author to cite the work of Mike Foote, who made some early important contributions to disparity in general, and has written papers that discuss some of these potential metrics (e.g., Foote 1997, Annual Review of Ecology and Systematics, 28, 129–). I believe Wills (2001, cited) also discusses a long list of metrics.}}

I agree, there are many more metrics commonly used for disparity analysis not implemented in this package.
This was a conscious choice: due to the really high number of metrics available (especially when combining different ones), I designed the package to be modular hence allowing users to implement their own metrics (see response to reviewer 1 minor comment \ref{table_missing}).
I have precise this using the hypercube volume example in the manuscript:

\textit{When multiple functions are passed to the} \texttt{metric} \textit{argument, the functions are sorted by dimension-level and applied in decreasing order to the data.
For example, if the metric is defined as} \texttt{metric = c(prod, ranges)} \textit{(the hyperbox volume), the} \texttt{ranges} \textit{function (dimension-level 2) is first applied to data (calculating the range of each dimension) and the function} \texttt{prod} \textit{is then applied to the results (e.g.} \texttt{prod(ranges(data))}\textit{).
If one needs to define the metric as something more complex, say the hypercube volume, one can directly pass a function description to the} \texttt{metric} \textit{argument (e.g.} \texttt{metric = function(x) min(ranges(x)) * ncol(x)}\textit{).}

I have however added several additional ones to the newest version of the package including the minimal spanning tree length (\texttt{span.tree.length} - as suggested), the ancestral distance which is equivalent to the distance from centroid but were the ``centroid'' are the coordinates of each element's ancestors (\texttt{ancestral.dist}), the pairwise distances (\texttt{pairwise.dist}), the radius which equivalent to the distance from centroids but for the dimensions (i.e. the distance between each dimensions coordinates and the mean dimension's coordinates - \texttt{radius}) and the $n$-ball volume which is an extension of the \texttt{ellipse.volume} function for a sphere (the true $n$-ball volume) or an ellipsoid (\texttt{n.ball.volume}).

\item{\textcolor{blue}{The package also employs a rarefaction function, but rarefaction can be problematic in the sense that rarefaction curves can sometimes cross such that the sampling level used to make comparisons can effect which of two or more subsets is considered the most disparate. This is why algorithms designed to sample "fairly" rather than equally have been explored, see for example Kotric and Knoll (2015, Paleobiology, 41, 68–). A user may also wish to rarefy by some external data source, such as number of occurrences, or geographic regions. These are obviously major additions, but are something the author might wish to add in future.}}

This is again an excellent suggestion!
I will develop more complex rarefaction algorithms based on sampling and occurrence based on methods applied empirically by Kotric and Knoll 2015 \textit{Palaeobiology} and Butler et al 2012 \textit{Evolution}.
I've added a note 

% %TG: TODO maybe!

\item{\textcolor{blue}{Other minor additions the author may also wish to consider are the permutation test from Brusatte et al. (2014, Current Biology, 24, 2386-), a means of adding the geologic timescale to time series plots (e.g., using the geoscale package)}}

I have added an illustrative example in the \texttt{plot.dispRity} manual on how to add disparity data (continuous or discrete) to the \texttt{geoscalePlot} and \texttt{geoscaleBox} functions thus allowing users to make ready-to-publish figures.

\item{\textcolor{blue}{and options for the user to only use a limited set of ordination axes (matrix columns), e.g., to avoid using higher axes with negative eigenvalues.}}

This option is implemented in the \texttt{boot.matrix} and \texttt{dispRity} functions allowing users to set a \texttt{dimensions} argument to either a proportion or a value of dimensions to use (e.g. \texttt{0.95} or \texttt{10} to use only the 95\% of the dimensions or the 10 first ones respectively). I've added a line highlighting this feature that is indeed often used:

\textit{Note that this function also allows to work on only a subset of dimensions via the} \texttt{dimensions} \textit{argument (e.g. if only the $n$ first dimensions must be considered).} l. @@@: 

\end{enumerate}

\subsection{Reviewer 2 - Minor comments}

\begin{enumerate}

\item{\textcolor{blue}{L4 - "in" should be "to"? "of variables" is then redundant and can be removed. L6 - "are the axis of this space" could just be "are the axes".}}

See reviewer 1 minor comment \ref{abstract_typo}.

\item{\textcolor{blue}{L7 - "a" here should be removed. L17 - "suits best" should be "best suits". L23 - "allowing to" should be "allowing users to". L28 - "suit" should be "suite".}}

I've fixed these typos.

\item{\textcolor{blue}{L54 - Technically a principal coordinates analysis *is* classic multidimensional scaling (CMDS). The author may also want to cite use of non-metric multidimensional scaling (e.g., Liow 2004, American Naturalist, 164, 431–).}}
\label{PCO_cites}

I have changed this sentence to:

\textit{These multidimensional spaces can be defined in many ways, for example as a pairwise distance matrix (Lloyd 2016 and references therein; e.g. in Close et al. 2015), or as outputs from an ordination, whether it being a principal components analysis (PCA, Hotelling 1933; e.g. in Zelditch et al. 2012), a metric scaling (PCO, PCoA, Torgerson 1958; e.g. in Brusatte et al. 2008) or a non-metric scaling (MDS, NMDS, Shepard 1962; e.g. in Liow 2004; Donohue et al. 2013).} lines @@@

\item{\textcolor{blue}{L80 - I'm not sure I would use the term "enforce" here. I think many of us write packages that serve our own needs, but the great thing about languages like R is that it is flexible and code can be borrowed and appropriated etc. Essentially I think the author may unintentionally disparage other package authors here. Besides which, I do not feel that dispRity is competing with other packages, rather it is supplemental to them. I.e., to repeat my comment from above I see dispRity as sitting at the end of a range of data analysis pipelines with other packages sitting in front of it.}}

I've change this sentence to:

\textit{package maintainers/software developers choose their preferred definition of multidimensional space and disparity metric to best it their needs (i.e. data, hypothesis, etc.) making the implementations sometimes hard to adapt to different needs.}  lines @@@

\item{\textcolor{blue}{L84 - Redundant "a".}}

I've fixed this typo.

\item{\textcolor{blue}{L116 - "??"!}}

Sincerest apologies! See reviewer 1 minor comment \ref{table_missing}.

\item{\textcolor{blue}{L130 - I don't think the term "possible observed" makes sense. Either the author means all the observed morphologies *or* all the possible morphologies. I suggest the former is safer as I think it likely that possible morphologies introduce sufficient complexity we can never really say this is true. For example, if we alter the number of elements in our sample (removing a species say) the ordination/morphospace we produce will differ, but the range of possible morphologies should not.}}

I agree and have changed it to ``\textit{all the observed morphologies}'' line @@@.

\item{\textcolor{blue}{L134 - Should probably be "an argument".}}

I have changed the start of the sentence to ``\textit{The first argument is the matrix}'' line @@@.

\item{\textcolor{blue}{L136 - It is not immediately obvious to me why a phylogeny is required here. This only becomes clearer later (time-slicing) so maybe a "heads up" parenthetic (i.e., "see below") could be added here.}}

I've modified the sentence in bracket to
``\textit{a dated phylogeny of the elements present in the morphospace - see below}'' (line @@@).

I've also changed the code to allow non-phylogenetic dating (e.g. just adding the First/Last Occurrence Dates of all the taxa) but I've only mentioned it in the function manual and the vignette due to space restriction in this manuscript.

\item{\textcolor{blue}{L208 - "looking at"? L213 - Should be "altitudinal"?}}
\label{altitude}

I've fixed these typos.

\item{\textcolor{blue}{L245-247 - I don't think these definitions for crown and stem are quite right. However, for the audience of MEE I suspect there is no need to define them so these parenthetic statements can just be cut.}}

I've removed the inaccurate definitions in parenthesis.

\item{\textcolor{blue}{L252 - It might be more helpful to define these using the phylogeny as this is a more generally applicable approach than manually delimiting row numbers (where human error can easily creep in or the inclusion of exclusion of data can mess things up). I.e., something that identifies descendants of the crown node and then a simple setdiff() between these and all possible names to get the non-crown (stem) taxa).}}

Great suggestion! I've added an utility function \texttt{crown.stem} allowing to separate stem and crown species.
The function is now briefly mentioned in the package description paper and detailed in the package itself.

\item{\textcolor{blue}{L296 - Should be "increase".}}

I've fixed this typo.

\item{\textcolor{blue}{L357 - Should be "for such analyses".}}

I've removed this last sentence (see reviewer 1 minor comment \ref{remove_last_sentence}).

\end{enumerate}






% ~~~~~~~~~~~~~~~~~~~~~~~~
%
% REVIEWER 3
%
% ~~~~~~~~~~~~~~~~~~~~~~~~






\section{Reviewer 3 (Michael Collyer)}

\begin{enumerate}

\item{\textcolor{blue}{The author presents a simple example and defers much of the many details users will encounter to his impermanent sources (vignettes, webpages), which I believe to be wise, as the R package will evolve.  I believe the purpose of a manuscript like this is illustrate its purpose and utility rather than serve as an instructional manual.  I believe the author has found the appropriate balance of instructional content between this manuscript and his other sources.}}


\item{\textcolor{blue}{The author acknowledged assistance with writing (suspect English is a second language) and the writing was great in the paper, but less so in the abstract.  Having someone double check the grammar in the abstract would be beneficial.  Also, line 116 refers to table ??.}}

\item{\textcolor{blue}{In the examples, replacing objects is not a good idea.  (This is also a problem in the help file examples in the R package.).  Remember that novice R users will use this software and might develop the habit of overwriting objects in the global environment, as updates.  It is possible to update objects with new names and retain the history during analyses, which is preferred in most cases and essential in others (for example, when a different analysis requires going back to a previously defined object.)  I recommend providing unique names.  For example, disparity is defined twice as an object on lines 255 and 261.  On line 261 it could be defined as DisparityB, and subsequently used without overwriting the object produced from a different function in line 255. Relatedly, one should not name objects the same name as functions.  This is simply bad news.  It is not something to encourage users to do.  Using "Disparity" rather than the function name, disparity, accomplishes the same thing without potentially causing problems down the line.  (The author will field requests for help from users, so this can be considered a pitfall avoided beforehand.)  This is discussed some here: https://stackoverflow.com/questions/6135868/in-r-what-exactly-is-the-problem-with-having-variables-with-the-same-name-as-ba}}

I have changed the variable names in the package description manuscript to not be redundant.
I've also changed the variable names in the package's help files to not override other functions/objects.

\item{\textcolor{blue}{It took me a bit of sleuthing for how the ANOVA on line 326 was performed. 
If I have one major concern, it is here. 
Rather than develop an, e.g., anova.test.dispRity S3 generic function, the author was able to use anova.lm by developing a way to coerce the output into a class "lm" object. 
This is clever but perhaps dangerous. 
For example, if one compares the results in Tables 3 and 4, they seem largely disparate. 
I would expect a statistically significant result, as one 95\% CI from Table 3 only slightly overlaps with the others, but an effect size of F = 177.84?? 
This is highly irregular, and I believe it is because of what the "lm" coercion does and what is actually tested here. 
My discomfort should have been readily apparent. 
The ANOVA df signals that what is performed is a parametric ANOVA on the bootstrapped group disparities across bootstrap iterations, as if these values are independent observations. 
The danger here must be appreciated.
Increasing the number of bootstrap iterations effectively and artificially increases statistical power (which I would argue should not be an objective). 
The ANOVA statistics are not based on the data but on the bootstrap results, which is not at all conventional (I could not find a source to confirm this approach). 
The normal procedure is to calculate a statistic, like an F statistic, in every bootstrap iteration and then draw inference from the distribution of that statistic, much like the "percentile bootstrap" (discussed some here:% \url{https://stats.stackexchange.com/questions/20701/computing-p-value-using-bootstrap-with-r/277391#277391}).
I believe that an ANOVA consistent with the confidence interval approach in Table 3 would bootstrap values in every permutation representing a null model (e.g., the values sampled come from a population with consistent mean and variance), calculate an F statistic based on among- and within-group disparities, then draw inference from the observed F value in the distribution of random outcomes.}}

% %TG: ANOVA problem

% As a minimum, this analysis should be called something different than " ANOVA performed on a dispRity object", which is rather terse, and I would be loathe to suggest that it tests the null hypothesis that disparity does not change through time, as suggested by the author.  In fact, it simply doesn't.  I came up with this simple example to illustrate why, according to the dispRity guidance:

% n <- 40
% p <- 10
% g <- as.data.frame(as.factor(rep(1:2, n)[1:n])) # generate groups
% Y <- matrix(rnorm(n*p), n, p)# generate random data with no pattern
% rownames(Y) <- rownames(g)
% cs <- custom.subsamples(Y, g) # customized subsamples
% bd <- boot.matrix(cs, bootstraps = 100) # bootstrapped data
% sv <- dispRity(bd, metric = c(sum, variances)) # sum_variances, as per directions

% anova(test.dispRity(sv, lm, "all")) # ALWAYS. A. SIGNIFICANT! RESULT!

% To state this plainly, garbage in equals a pattern out.  This happened with every permutation I ran and the result was usually a huge effect size similar to that reported in the manuscript.  

\textcolor{blue}{I can see no reason to perform ANOVA like this.  I'm not sure what it helps.  I stopped here in terms of my sleuthing but I wonder what other analytical short-cuts like this could cause problems. This is important!  As the author noted, and I agree, there is a paucity of development in this area.  One of the reasons might be that it takes time to bench test methods.  Surveying our functions in geomorph will reveal many methodological papers cited along with functions.  We release functions once we feel they are theoretically sound.  Introducing methods that have not been vetted will lead users to make dangerously incorrect inferences.  This is a difficult job but it has to be done.  While I'm excited to see this package released, to release it with known flawed analytical functions introduces a much larger mess to clean up later.  My recommendations are these:}

\begin{itemize}
\item \textcolor{blue}{1) Remove these ANOVA results from the manuscript, which do not enhance the confidence intervals much at all.}

\item \textcolor{blue}{2) Consider removing underdeveloped functions or arguments from your package until you have had sufficient time to test them.  Release them along with subsequent manuscripts that show you have tested type 1 error rates and statistical power.}

\item \textcolor{blue}{3) Or (and less recommended), put very stark and clear warnings that statistical results produced by some of these functions have not been tested and the user bares some risk making inferences from them.}

\end{itemize}

The ANOVA problem is totally a garbage-in-garbage-out problem and I agree with this reviewer that this might be a serious problem down the line.

Unfortunately, I do not have any proper solution to propose to this problem and I guess multidimensional distributions comparisons methods needs yet to be developed!

The reason for these crazy high degrees of freedom come from the bootstrapping pseudo-replication: effectively, the test data contains all the bootstrap data.
One solution is to use the concatenate = FALSE option in test.dispRity, performing the test for each bootstrap replicate rather than pooling the data.
This methods outputs a distribution of test that can be used to assess the type I error.
However, the pooling of the p-value is not satisfactory either.

Some methods exists such as NPMANOVA (from vegan::adonis) but is performed on the wrong kind of matrix.

One of the reasons for this functionality in the package is to make the test.dispRity function modular like the other main functions: i.e. it \textit{can} apply a \textit{lm} class function to the data but the reason for doing that might be dubious (or not, if the users don't bootstrap the matrix for example).

%TG: I therefore removed the example in the manuscript and the manual to not mislead users into running flawed analysis. However, I've left the architecture implemented for adventurous (or clever) users.
% Remove the ANOVA example
% Remove mentions to it on bootstrapped data in the manuals
% Replace by more savy example
% Allow to use NPMANOVA instead
%
% Dissimilarity analyses: ANOVA using dissimilarities, ANOSIM, MRPP, BIOENV, Mantel and partial Mantel tests.
% Ordination and environment: vector fitting, centroid fitting and smooth surface fitting, adding species scores as weighted averages, adding convex hull, SD ellipses, arrows etc. to ordination.
% Ordination: support and meta functions for NMDS, redundancy analysis, constrained correspondence analysis, constrained analysis of proximities (all three with partial analysis),


\item{\textcolor{blue}{I also have a recommendation for the package, itself, based on my experiences. 
The author should strive to make arguments and function details clearer to users, especially as using dispRity requires a lot of integration between different functions. 
Also, it is a bit of an art, but one to be practiced, to use print.\_ S3 generic functions. 
I tried to compare some of the dispRity functions to morphol.disparity in geomorph for known data sets. 
Below are results (which show that t.tests on disparities seem to produce similar results to morphol.disparity, as expected). 
I use this juxtaposition to demonstrate a subtle difference. 
A novice user will have no idea what [[1]] and [[2]] means as output, and even though I consider myself fairly experienced with R, I had to go run a t.test on some data to remind myself that "statistic" is the t-stat and "parameter" means the degrees of freedom. 
I'm not sure what the confidence intervals on df should inspire but I respect that in this case - unlike my criticism above - it appears that the bootstrapped outcomes are on all values provided by a t.test in each iteration. 
Regardless, this complexity begs for direction. 
Although the geomorph results by comparison were tedious to achieve, I can attest that it saved a lot of time spent working with users to understand results. 
The author should remember that once this manuscript is published, this R package becomes a dedication to the researchers who use it. 
Cleaning up some of these details now will make it easier to remain dedicated later.}}

I have changed the \texttt{test.dispRity} to now output the name of the statistic and the parameter in the output list (e.g. \texttt{statistic: t} and \texttt{parameter: df} for the example provided by the reviewer).
I have also highlighted in the manuscript one of the features of the function allowing to output the results in a format more familiar to the user using the option \texttt{details = TRUE} (returning the raw test results):

\textit{Note that by default the function only outputs the test's statistic, parameter (if parametric) and the p value. However, the raw test results can also be output using the option} \texttt{details = TRUE} \textit{in the function above.} lines @@@

\end{enumerate}



% I hope these comments are helpful and I look forward to seeing this package fully developed!  My recommendation would be to accept this manuscript with minor revision, if not for the one major issue I had with the ANOVA method.  I hope I have made my concern clear and it is otherwise clear that I believe this manuscript would be a nice contribution to MEE upon revision.

% Sincerely,
% Michael Collyer

% test.dispRity(disparity_var, test = t.test, comparisons = "pairwise",
% +               concatenate = FALSE, correction = "bonferroni",
% +               conc.quantiles = c(mean, c(95)))
% [[1]]
%                                                   statistic       2.5%     97.5%
% plethodon$species.Jord : plethodon$species.Teyah -0.06351374 -0.6744747 0.5683461

% [[2]]
%                                                 parameter     2.5%    97.5%
% plethodon$species.Jord : plethodon$species.Teyah  43.15056 36.62182 45.99247

% [[3]]
%  p.value      2.5%     97.5% 
% 0.7956904 0.4691708 0.9976864 

% morphol.disparity(Y~groups , ~groups, data = gdf)
%  |=================================================================================================================| 100%

% Call:
% morphol.disparity(f1 = Y ~ groups, groups = ~groups, data = gdf) 



% Randomized Residual Permutation Procedure Used
% 1000 Permutations

% Procrustes variances for defined groups
%       Jord       Teyah 
% 0.004149811 0.004234284 


% Pairwise absolute differences between variances
%              Jord        Teyah
% Jord  0.000000e+00 8.447277e-05
% Teyah 8.447277e-05 0.000000e+00


% P-Values
%       Jord Teyah
% Jord  1.000 0.876
% Teyah 0.876 1.000









% ~~~~~~~~~~~~~~~~~~~~~~~~
%
% REVIEWER 4
%
% ~~~~~~~~~~~~~~~~~~~~~~~~







\section{Reviewer 4 (Gavin Simpson)}

\begin{enumerate}

\item{\textcolor{blue}{I have several concerns regarding the content in the manuscript, however, primarily how it is pitched.
It seems unclear, to me at least, who the intended audience is?
At various points I get the impression that the author intends for the package to be useful, and therefore, presents it, to readers beyond those studying morphometry etc.
There are frequent references to ecology and related disciplines where similar approaches are used.
Yet, those in these broader fields will struggle to follow what is presented as the manuscript exclusively uses "morphospaces" and related terminology that will only be relevant to a specific subset of readers.If you want to aim for a more general audience, consider rewriting the manuscript in more general terminology; samples in rows, variables in columns, for example.
Perhaps include a table to relate terminology used in morphometry with that more commonly encountered in community ecology.
Consider adding an ecological example and removing, if length is an issue, content on the manual and vignette --- we don't really need a paragraph on that, just a sentence to highlight it exists.}}

I have worked towards making the manuscript more useful for non-morphologists.
I have generalised the input description as suggest by this reviewer, minor comment \ref{rows}; added a glossary table and a brief example using ecological data.
%TODO: add Diaz's example?
% %TG: adding an ecology example (removing manual and vignette description)

\item{\textcolor{blue}{The referencing is poor; why cite Close et al for the concept of pairwise distances?
I'm pretty sure PCO existed before Brusatte et al, and PCA certainly before 2012, etc.
Throughout I was frustrated with this; the referencing ignores a century of work outside this specific field.
I appreciate there merit in citing relevant literature for your field, but that doesn't absolve one of a duty to accurately attribute ideas to those that came up with them.
If you are unfamiliar with developments in ideas beyond your particular field, I would suggest Legendre \& Legendre's *Numerical Ecology* textbook as a good source for original work relevant to what is presented here.}}

I thank this reviewer for sharing the excellent Legendre \& Legendre reference (that was definitely a reference I was missing) and I've accurately credited the statistical methods throughout the manuscript - see my response to reviewer 2, minor suggestion \ref{PCO_cites}.

\item{\textcolor{blue}{The comparison or critique of packages that, in the eyes of the author, restrict users grated a little with me. As a developer of one of the packages named, I feel that particular critique is unwarranted for several reasons;
\begin{itemize}
\item i) **vegan** doesn't restrict you at all, as with anything in R you are free to pick and choose ordination methods, dissimilarity measures etc and then do what you want with the scores,
\item ii) **vegan** doesn't provide disparity measures because it was never intended for such usage, but it is general enough that a user could do whatever they want,
\item and iii) like any software, the **dispaRity** author's software included, you have to provide defaults and **vegan**'s defaults reflect the intended audience of community ecology; that's a feature, as it is of **dispaRity**. As such the argument set up on page 6 is some straw man and unnecessary to motivate your package.
\end{itemize}
}}

I apologise for the unfounded critique and I have toned down this sentence (see reviewer 1, minor suggestion \ref{tone_down}).
% Additionally, I have added more functionalities using vegan and geiger %TODO!
% %TG: Tone down the critics to other packages

\item{\textcolor{blue}{You don't really define disparity anywhere, except in very loose terms.
This needs making more explicit; I appreciate that disparity is a broad, nebulous concept, but you need to help the reader that may not be familiar with your subject area.
Either that or as mentioned above, refocus the paper on those readers already versed in this particular type of analysis.}}
\label{nebulous}

I have tried to define disparity with more examples and references to be more familiar to a broader range of readers (See reviewer 1, major suggestion \ref{define_disparity}).

%TG: explain disparity

\item{\textcolor{blue}{Something that I did miss, which is at the forefront of my mind as a lot of work has gone into **vegan** in this area, is how you handle negative eigenvalues and their eigenvectors?
Typically, one needs to account for these issues, which readily arise when embedding data in an Euclidean space (via PCO) using a non-metric dissimilarity.
Does **dispaRity** handle such problems, and if so how?
If not, is this because those steps are left up to the user to deal with?
If so, there are some issues that cannot be corrected by the user without strongly biasing the results of the analysis.
This is one area where there is the potential for the ideal of being accommodating of users can cause problems downstream if you are not in control of issues like non-metric dissimilarities.
An example where it needs specific handling is in multivariate dispersions (distances around centroids), but even simple ordinations based on dissimilarities require special handling.}}

%TOD: add a note to the paper and the package (warnings if negative eigen values).
%TG: negative egein values explnations
% Check Legendre and Legendre pp.449

\end{enumerate}

\subsection{Reviewer 4 - Minor comments}

\begin{enumerate}

\item{\textcolor{blue}{L17: insert "ability" between "researchers" and "to", and swap order of "suits" and "best" to read "best suits".}}

I've fixed these typos.

\item{\textcolor{blue}{L50: Here is an opportunity to bridge to the community ecology field and make more general statements regarding multivariate data; rows and samples or observations, columns are variables or some function of variables such as an embedding (PCO) or an ordination.}}

I've changed the sentence to:
\label{rows}

\textit{In all these analysis, each set of multivariate traits forms a multidimensional space. This space is represented as a matrix where rows are regarded as samples or observations (e.g. a specimen, field sites, etc.) and columns are variables or some transformation thereof (e.g. an embedding, scaling, ordination, etc. of the variables).}

\item{\textcolor{blue}{L51--54: here referencing is very poor. Please cite relevant original research. Also, expand on what you mean by MDS; is this different from PCO, which also goes by this name --- do you mean NMDS here?}}

I went with Legendre \& Legendre 1998's definition of ordinations (pp. 388) in the three major distinct categories: (1) principal components analysis (PCA), (2), principal coordinates and metric scaling (PCO, PCoA) and non metric dimensional scaling (NMDS, MDS), ignoring correspondence and factor analysis for clarity. See reviewer 2, minor suggestion \ref{PCO_cites}.

\item{\textcolor{blue}{L65--64 here are additional areas where referencing is poor. Consider Marti Anderson's work on multivariate ANOVA \& dispersions as earlier work, for example:
\begin{itemize}
\item Anderson, M. J. A new method for non-parametric multivariate analysis of variance. Austral Ecol. 26, 32–46 (2001)
\item Anderson, M. J. Distance-based tests for homogeneity of multivariate dispersions. Biometrics 62, 245–253 (2006).
\item Anderson, M. J., Ellingsen, K. E. \& McArdle, B. H. Multivariate dispersion as a measure of beta diversity. Ecol. Lett. 9, 683–693 (2006).
\end{itemize}
}}
\textcolor{blue}{For permutation tests, significant work has been done in this area by Cajo ter Braak, principally in his Canoco software and related publications.
Also comparing overlap in CIs is a terrible way to perform inference; for 95\% confidence intervals, if the intervals for two estimated means are as close as possible but not overlapping, the p value of the difference means test is 0.005, not 0.05. To achieve 0.05 you can allow considerable overlap, but how much is tricky to discern by eye.
As such you are at risk of making poor choices on the basis of perceived significance.}

I have changed this sentence by citing Anderson 2001 \textit{Austral Ecol.} and Manly 1997 \textit{Randomization, bootstrap and Monte Carlo methods in biology}.
I also totally agree with the poor choice of simply comparing CIs; unfortunately this method is not that uncommon common in palaeobiology.
I've removed the citation (to avoid pointing-and-shaming) and added a caveat to this way of comparing disparity:

\textit{[...] an equal variety of statistical tests such as non-parametric multivariate analyses of variance (NPMANOVA, Anderson 2001 ; e.g. in Brusatte et al. 2008) multidimensional permutation tests (Manly 1997 ; e.g. in Díaz et al. 2016) or even, less rigorously, by looking at the confidence interval overlaps between disparity measurements.}

\item{\textcolor{blue}{L116 There is either a missing reference or a missing table, I presume the latter as no existing table matches the textual description in and around this line.}}

Sincerest apologies! See reviewer 1 minor comment \ref{table_missing}.

\item{\textcolor{blue}{L134 Needs "an" between "as" and "argument". L210 delete "sheer". L213 "longer" not "bigger" and "altitude" not "altitudes". L218 "longer" not "bigger"}}

I've fixed these typos (see also reviewer 2 minor comment \ref{altitude}).

\item{\textcolor{blue}{L252 and throughout the code: insert straight quotes. There is a good chance these curly quotes will get replaced with some non-ASCII character and be impossible to paste into R.}}

I've converted all quotes in quoted code lines as ASCII straight quotes.

\item{\textcolor{blue}{In the example around L236--249, can you justify the metric used here? Is the sum of variances along components of an ordination a valid measure of the dispersion in multivariate space of samples? You don't, or I didn't see, reference to original work that justifies this, and it's not something I have come across despite implementing some approaches for testing multivariate dispersion in the **vegan** package. Doesn't this suffer the same problem as confidence bars in an x-y scatterplot where the bars have been defined with reference to only one axis at a time? The solution is a confidence ellipse, which is often quite different to the interval implied by separate confidence interval bars for each axis.}}

This metric (the sum of each ordination axis variance) is commonly used in palaeobiology (since Foote 1991 and Wills et al. 1994) probably due to a ``citation diffusion effect'' (i.e. future authors replicating convincing methods) and partly due to its pretty good behaviour with palaeontological data (e.g. missing data, Ciampaglio 2001).
However, as this reviewer high

%TG: justify from palaeo litterature? + add a note "One of the caveats of such method is that it implicitely ignores the covariance between the ordination axis."

\item{\textcolor{blue}{L294 replace "following up" with "subsequent"}}

I've changed the sentence following this suggestion.

\item{\textcolor{blue}{L323 This statement seems overly vague. What level of confidence is there in this test? The 95\% intervals overlap throughout, and although you don't show then, one can infer that say the 0.2 probability quantile of subsample 2 overlaps with the 0.975 quantile of sub sample 1.}}

%TODO

\item{\textcolor{blue}{L326 Where do the 300 samples come from as implied by the residual degrees of freedom. Table 3 suggests 15 + 9 + 13 = 37 samples in this analysis. I'm clearly missing something here. Also, this is an omnibus test, which if we believe the printed values (see previous re DF) only says there is some effect of `subsamples`. Can this analysis be extended to point estimates for mean variance (again assuming you can justify this sum of individual variances method) and post-hoc comparisons of pairwise `subsample` differences, which would be quite useful?}}

%TODO correct/explain this 300 subsamples + add a posthoc t-test.

\item{\textcolor{blue}{If you need to save space to add an ecological example, cut the *Manuals and vignettes* section and also the *Data simulations* section. The later is somewhat tangential to the main thrust of the paper and you cover this in the vignette/bookdown resources.}}
\label{remove_simulations}

I have removed the simulations part as suggested by this reviewer.
However, following the encouraging suggestions of reviewer 2 (major suggestion \ref{simulations}) I have developed in much more details the simulation algorithms in the package manual.

\end{enumerate}

\end{document}
